{"/":{"title":"","content":"# Literature Notes\n\nThis is a repository with papers and other links as well as some notes on them. People can always add notes, so this is a bit of a living document. This folder is set up as an obsidian vault. Each paper has its own folder with a README summary, the PDF paper (often), and any other related materials.\n\nThe main tags are the research phases from TCER:\n\n- Theoretical CER\n  - **#phase-1a**: General or borrowed theory\n  - **#phase-1b**: CE-specific theories\n- Experimental CER:\n  - **#phase-2a**: Designed artifacts for controlled experiments\n  - **#phase-2b**: Controlled experiments\n- Research Synthesis:\n  - **#phase-3a**: Academic literature reviews\n  - **#phase-3b**: Practitioner-facing guides\n- Applied CER:\n  - **#phase-4a**: Evidence-based prototypes\n  - **#phase-4b**: Practitioner reports and feedback\n- Impact at Scale:\n  - **#phase-5a**: Scaled interventions\n  - **#phase-5b**: Reports and feedback\n\nThere are three additional tags for CER references that are not research or interventions:\n\n- **#reflexive**: Introspective references that are _about_ CER as a field.\n- **#outreach**: Outreach efforts from the CER community that are not specifically about sharing best-practices\n- **#phase-XY-tz**: References from another field but are related to or inspiring for CER. The `XY` can be replaced by any TCER phase, and the `tz` stands for \"_trading zone_\"\n","lastmodified":"2022-11-11T17:42:06.194454507Z","tags":null},"/analyzing-fine-grained-material-usage-behavior/README":{"title":"","content":"# Analyzing Fine-Grained Material Usage Behavior, Koutcheme et al, 2021\n\n2 pages\n\navailable at: https://cssplice.github.io/SIGCSE21/proc/SPLICE2021_SIGCSE_paper_4.pdf\n\n[the paper](the-paper.pdf)\n\nIn contrast to previous research, using IDEs themselves to gather log data on student activity, this study looks at logs from online textbooks (and web-based materials in general).\n\nMost interesting part is the actual log data, comprised of\n- User Id\n- timestamp\n- event type\n- first visible element\n- last visible element\n- top Y coordinate\n- page URL\n\nPresumably, this involved students who had opted in to data collection, since they were only collecting data in one class, though what if we wanted a general method to push data like this to a central system. The biggest issue would probably obtaining consent, and how to phrase it, since most people are now familiar with the GDPR-cookie consent popup (at least in the EU), but would we have an additional popup or just assume the consent for cookies equals consent for this other type of data collection? In theory, as long as there is no personally identifiable information, then we wouldn't be beholden to GDPR compliance requirements, but it's unclear what data we would be interested in, so making that determination is a bit difficult.\n\nThe original javascript component used involves jquery, though if we used something like open telemetry (https://opentelemetry.io/docs/instrumentation/js/getting-started/browser/), that might be a bit more robust. It would also allow for a uniform format of data pushed somewhere.\n","lastmodified":"2022-11-11T17:42:06.194454507Z","tags":null},"/crowdsourcing-content-creation-for-sql-practice/README":{"title":"","content":"# Crowdsourcing content creation for SQL practice (Leinonen, Pirttinen \u0026 Hellas, 2020)\n\n\u003c!-- they describe the design they built just for themselves --\u003e\n\n#phase-4a\n\n\u003c!-- they gathered feedback and report on it --\u003e\n\n#phase-4b\n\n[the paper](./the-paper.pdf)\n\nhttps://research.aalto.fi/files/54408038/SCI_Leinonen_Crowdsourcing.ITiCSE_2020_SQL_trainer.pdf\n\n7 pages\n\nStates that there are not large differences between crowdsourced content created by novices and experts, or in this specific case, students and teachers. Implies that a system of creating/presenting/assessing these at web-scale would not only be feasible, but effective.\n\nPoints out that one of the main uses of crowdsourcing is to minimize time needed for content generation during each course iteration.\n\nPeerwise is one of the mentioned examples, but it seems to be behind an institutional login, minimizing the overall accessibility. Presumably this is an effort at content-moderation, eliminating anonymous user submissions.\n\nAlso mentiones Crowdsorceror (a project available on GitHub as a frontend in React and backend in Rails) for students to submit templates and tests for programming assignments. Seems defunct, but another good idea. If we can set up a sandbox runtime for actually evaluating templates and turning them into runnable code, we can assert submissions against tests. This might be what we need GitPod for, since that's already sandboxed by default ... :thinking:\n\nThe method of assessment for the actual work done in the paper is to create two in-memory databases for each submission: one with the expected outcome of the \"correct\" sql query, and one with the outcome of the student's submitted query. They're probably talking more about \"views\" on a table, in postgresql's definition. Provided that the underlying data is the same, we want to compare the diff of a view (query) against that data with the one the student submits. Depending on where we host/run this, the cost implications are probably vastly different. And any reasonably-sized application doing this would need to take great care to limit the potential for SQL-injection attacks, possibly via parameterized queries and other mitigations.\n\nThe topics included simple SQL select statements on one or more tables, comparisons for limiting results, constructing aggregate queries, constructing nested queries, and altering the database schema (cre-ating, removing, updating tables, working with indices). In total, the teacher generated 45 SQL assignments into the system.\n\nthis would have been cool to try and run, but it's written in java and requires an Oauth server, so may attempt to reimplement at some point in another language.\n","lastmodified":"2022-11-11T17:42:06.194454507Z","tags":null},"/exploring-the-use-of-faded-worked-examples-as-a-problem-solving-approach-for-underrepresented-students/README":{"title":"","content":"[example link](../psychometric-principles-in-student-assessment/psychometric-assessment.md)\n\n# Exploring the use of faded worked examples as a problem solving approach for underprepared students\n\n\u003c!-- borrowing from chemistry --\u003e\n\n#phase-2a-tz\n\n#phase-2b-tz\n\n[the paper](./the-paper.pdf)\n\nhttps://files.eric.ed.gov/fulltext/EJ1086007.pdf\n\n11 pages\n\nFocused on Chemistry, but broadly applicable as a framework for presenting certain types of programming problems via a web-UI.\n\nShows not only the actual calculation to be applied at each step, but a prose-description of what's happening. There was a _little_ bit of \"why\" given here (reminded of labelled sub-goals), but it was a bit difficult to parse out.\n\nShowed the that underperforming group ended up outperforming the originally \"advanced\" group in both categories in the final exam (multiple choice and open-ended questions).\n\nThe intervention amounted to an additional 17.5 hours of instruction over the course of 14 weeks, so it's very possible that also contributed to the results.\n\nFor our purposes, would be interesting to see what types of problems lend themselves to the worked example format, and further, if there's a particular data structure to return from an API that would allow a web-based frontend to consume and programmatically present these as activities for learners.\n","lastmodified":"2022-11-11T17:42:06.194454507Z","tags":null},"/grand-theories-or-design-guidelines/README":{"title":"","content":"# Grand Theories or Design Guidelines\n\n\u003c!-- borrowing from chemistry --\u003e\n\n#reflexive\n\n[the paper](./the-paper.pdf)\n","lastmodified":"2022-11-11T17:42:06.202454531Z","tags":null},"/psychometric-principles-in-student-assessment/README":{"title":"","content":"# Psychometric Principles in Student Assessment (Mislevy, et al. 2003)\n\n\u003c!-- assessment theory from another field --\u003e\n\n#phase-1a-tz\n\n#phase-2a-tz\n\n[the paper](./the-paper.pdf)\n\nhttps://www.researchgate.net/publication/251470314_Psychometric_Principles_in_Student_Assessment\n\n69 pages\n\nProvides a good overview on the connection between the construct (what we assume the students knows, can do) and the observable behavior present in the task, which is measured (assessed) by reference to the rubric.\n\nUnfortunately missing a bunch of figures, since this is likely a pre-publication draft, though the discussion is very clear and easy to follow.\n\nMakes very clear that the data for assessments is observable behavior of the student.\n\n- The Student Model: What complex of knowledge, skills, or other attributes should be assessed?\n\nFor our purposes, this is one of the main questions we need to figure out. There isn't a lot of great research on \"what do programmers do?\" or \"what makes a good programmer?\". In that sense, measuring the product is a more straightforward way to assess skills (highly reliable, but potentially less valid). If we assume that web developers need to be able to:\n\n- use the chrome console to debug errors\n- use async functions in typescript code\n- read code in order to add a new feature\n\nthen it's a good starting point to define the end state, but it doesn't tell us a lot about how to go about practicing doing that, nor if there are any intermediate steps along the way to further decompose the task.\n\nThe \"Task Model\" as presented in this paper is a lot closer to the above \"objectives\", but again, there doesn't seem to be much existing research enumerating what working programmers actually need to do, nor is it very clear how this research would be conducted and what the methods would be (questionnaires? observation? something else that's actually scalable?).\n\nGoes into a fair bit of depth on the statistical models underpinning reliability, though has a very nice section on Item Response Theory and how it tells us about the particular configuration of items (basically which distractors are good and which items are telling us useful information).\n\nDoesn't go into any detail about how to choose relevant constructs/tasks, though this has important implications for the learning objectives, and vice versa, but as an introductory paper to someone who isn't familiar with general psychometric principles, it's very good.\n","lastmodified":"2022-11-11T17:42:06.202454531Z","tags":null},"/struggles-of-college-graduates-in-their-first-software-development-job/README":{"title":"","content":"# Struggles of new college graduates in their first software development job (Begel and Simon, 2008)\n\n\u003c!-- real-world observations --\u003e\n\n#phase-4b\n\n\u003c!-- recommendations for practitioners --\u003e\n\n#phase-3b\n\n\u003c!-- domain-specific CE theories --\u003e\n\n#phase-1b\n\n[the paper](./the-paper.pdf)\n\nhttps://www.researchgate.net/publication/221537616_Struggles_of_new_college_graduates_in_their_first_software_development_job\n\n5 pages\n\nMentions prior research suggesting that developers spend a lot of time interacting with others in order to fill their purely \"technical\" software creation activities.\n\nHighlights hypothesis generation (P and possibly I of PRIMM) as an authentic developer task.\n\nInteresting that one of the very common technical challenges was working with version control (probably because nobody teaches git in university).\n\nDiscusses the vast differences between team projects at universities (completely new and greenfield) with real-world assignments in pre-existing legacy systems with lacking documentation and situated in sociotechnical and political contexts. It would be much more valuable to present students with large pre-existing codebases with bugs that need to be triaged and fixed.\n\nA particularly interesting note is the recommendation to explicitly teach the process of finding, documenting and triaging bugs **without** fixing them immediately.\n\nFor our purposes, given that one of the major findings was that non-technical issues of collaboration and interaction were something students needed more work with, a learning space approach with contextualized collaboration as a necessary condition and aspect of the environment is supported by this work.\n","lastmodified":"2022-11-11T17:42:06.206454543Z","tags":null},"/teach-computing-curriculum/README":{"title":"","content":"\u003e stubby stub\n\n#phase-5a\n\nhttps://teachcomputing.org/curriculum\n","lastmodified":"2022-11-11T17:42:06.206454543Z","tags":null},"/the-role-of-orientation-and-self-efficacy-in-learning-from-web-based-worked-examples/goals-and-self-efficacy-with-worked-examples":{"title":"","content":"# The role of goal orientation and self-efficacy in learning from web-based worked examples (Crippen et al., 2009)\n\n\u003c!-- borrowing from chemistry --\u003e\n\n#phase-1a-tz\n\n#phase-2a-tz\n\n#phase-2b-tz\n\n#phase-4a-tz\n\n[the paper](./the-paper.pdf)\n\nhttps://www.researchgate.net/publication/234648697_The_Role_of_Goal_Orientation_and_Self-Efficacy_in_Learning_from_Web-Based_Worked_Examples\n\n19 pages\n","lastmodified":"2022-11-11T17:42:06.210454556Z","tags":null},"/time-on-task-metrics-for-predicting-performance/README":{"title":"","content":"# Time on task metrics for predicting performance (Leinonen, Castro \u0026 Hellas, 2022)\n\n\u003c!-- they develop a CE-specific learning theory --\u003e\n\n#phase-2b\n\n\u003c!-- not 2a because they don't go in depth on a thing they built for the experiment --\u003e\n\n[the paper](./the-paper.pdf)\n\nhttps://research.aalto.fi/en/publications/time-on-task-metrics-for-predicting-performance\n\n8 pages\n\nDiscusses use of log data collected via the IDE for students during task completion. The two main measurements are:\n\ncoarse-grained time on task (time from first keystrok to submission of exercise)\nfine-grained time on task (sum of latencies between keystrokes until submission of exercise, with all breaks of 10+ minutes removed)\n\nThe results support the assertion that _in this particular context_, the finer-grained data was more predictive of success in the course summative assements.\n\nHowever, it doesn't tell us anything about whether those assessments are in any way valid, or are actually measuring relevant constructs about the students' learning.\n\nFor our purposes, we would more easily be able to collect coarse-grained data (as defined above) in a web-app type of assessment instrument, since that's basically just two timestamps. Though it's an open question as to whether a very simple micromaterial is comparable to a more full-featured programming assignment (as was the object of study in this paper).\n","lastmodified":"2022-11-11T17:42:06.210454556Z","tags":null}}